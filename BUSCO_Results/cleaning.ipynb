{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2e4bf0-f906-4a51-84d2-a5e202daccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       # Busco id      Status        Sequence  Gene Start  Gene End Strand  \\\n",
      "0        15at3041    Complete  QOKY01000184.1    218487.0  205577.0      -   \n",
      "1        42at3041    Complete  QOKY01000215.1    154691.0  162368.0      +   \n",
      "2        45at3041    Complete  QOKY01000197.1    663944.0  649124.0      -   \n",
      "3        52at3041    Complete  QOKY01000213.1    408354.0  402296.0      -   \n",
      "4        64at3041    Complete  QOKY01000154.1     11853.0   10296.0      -   \n",
      "...           ...         ...             ...         ...       ...    ...   \n",
      "1518  12685at3041    Complete  QOKY01000158.1    274297.0  274588.0      +   \n",
      "1519  12851at3041  Fragmented  QOKY01000173.1    348117.0  347938.0      -   \n",
      "1520  12893at3041    Complete  QOKY01000128.1    382082.0  382409.0      +   \n",
      "1521  13024at3041    Complete  QOKY01000142.1     50576.0   50269.0      -   \n",
      "1522  13052at3041    Complete  QOKY01000202.1    375212.0  373638.0      -   \n",
      "\n",
      "       Score  Length                                    OrthoDB url  \\\n",
      "0     3907.4  1965.0     https://www.orthodb.org/v10?query=15at3041   \n",
      "1     2048.5  1129.0     https://www.orthodb.org/v10?query=42at3041   \n",
      "2     1879.8  1448.0     https://www.orthodb.org/v10?query=45at3041   \n",
      "3     2093.7  1312.0     https://www.orthodb.org/v10?query=52at3041   \n",
      "4      325.5   217.0     https://www.orthodb.org/v10?query=64at3041   \n",
      "...      ...     ...                                            ...   \n",
      "1518   101.1    50.0  https://www.orthodb.org/v10?query=12685at3041   \n",
      "1519    59.0    41.0  https://www.orthodb.org/v10?query=12851at3041   \n",
      "1520    79.2    67.0  https://www.orthodb.org/v10?query=12893at3041   \n",
      "1521   107.5    42.0  https://www.orthodb.org/v10?query=13024at3041   \n",
      "1522   180.9   224.0  https://www.orthodb.org/v10?query=13052at3041   \n",
      "\n",
      "                                   Description  \n",
      "0        Pre-mRNA-processing-splicing factor 8  \n",
      "1                Magnesium chelatase subunit H  \n",
      "2     DNA polymerase epsilon catalytic subunit  \n",
      "3                         Clathrin heavy chain  \n",
      "4                            predicted protein  \n",
      "...                                        ...  \n",
      "1518          type II secretory pathway family  \n",
      "1519                          Copper chaperone  \n",
      "1520       Signal recognition particle protein  \n",
      "1521      U1 small nuclear ribonucleoprotein C  \n",
      "1522                         predicted protein  \n",
      "\n",
      "[1523 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('full_table_Auxenochlorella_protothecoides_UTEX25.tsv', sep='\\t', skiprows=2)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "374910e6-bd6e-41e0-b959-f9c27553eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove \"Duplicated\" duplicate entries. \n",
    "import csv\n",
    "\n",
    "with open('full_table_Auxenochlorella_protothecoides_UTEX25.tsv', 'r') as input_file, open('Duplicated_Auxenochlorella_protothecoides_UTEX25.tsv', 'w') as output_file:\n",
    "    reader = csv.reader(input_file, delimiter='\\t')\n",
    "    writer = csv.writer(output_file, delimiter='\\t')\n",
    "    seen = set()\n",
    "    for row in reader:\n",
    "        if row[0] not in seen and 'Duplicated' in row:\n",
    "            writer.writerow(row)\n",
    "            seen.add(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f642c-c313-40e4-b96c-342e28b4e122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a84b96-7aaa-4248-b496-c1eb8866d517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c150cc7-4285-4839-ba5c-d37a6f73ca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4423at3041  Duplicated  QOKY01000130.1  365295  363899  -  261.1  203  \\\n",
      "0   6268at3041  Duplicated  QOKY01000133.1  175358  173921  -  272.7  228   \n",
      "1   6347at3041  Duplicated  QOKY01000135.1  625963  626977  +  122.2  190   \n",
      "2  10334at3041  Duplicated  QOKY01000142.1  166207  166686  +   88.6   99   \n",
      "\n",
      "    https://www.orthodb.org/v10?query=4423at3041  \\\n",
      "0   https://www.orthodb.org/v10?query=6268at3041   \n",
      "1   https://www.orthodb.org/v10?query=6347at3041   \n",
      "2  https://www.orthodb.org/v10?query=10334at3041   \n",
      "\n",
      "                           Methionine aminopeptidase  \n",
      "0  4-hydroxybenzoate polyprenyltransferase, mitoc...  \n",
      "1                      MIF4G-like domain superfamily  \n",
      "2                                n-acetyltransferase  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df2 = pd.read_csv('output_file.tsv', sep='\\t')\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c93b673-20ce-4fc0-bc97-8cb5dbf8208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['Auxenochlorella_protothecoides_UTEX25', 'Auxenochlorella_pyrenoidosa_FACHB9', 'Chlorella_A99', 'Chlorella_Dachan', 'Chlorella_KRBP', 'Chlorella_sorokiniana_1602', 'Chlorella_variabilis_NC64A', 'Chlorella_vulgaris_21111P', 'Coccomyxa_subellipsoidae_C169', 'Helicosporidum_sp_ATCC50920', 'Micractinium_conductrix_SAG24180', 'Scenedesmus_PABB004', 'Trebouxia_gelatinosa_LA000220', 'Trebouxiophyceae_KSI1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb1804-d790-4852-be2c-4860469912cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9bf3de-ad64-4fb8-b748-b350dd87a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "for specie in species_list:\n",
    "    with open(f'full_table_{specie}.tsv', 'r') as inputfile, open(f'Duplicated_{specie}.tsv', 'w') as outputfile:\n",
    "        reader = csv.reader(inputfile, delimiter='\\t')\n",
    "        writer = csv.writer(outputfile, delimiter='\\t')\n",
    "        seen = set()\n",
    "        for row in reader:\n",
    "            if row[0] not in seen and 'Duplicated' in row:\n",
    "                writer.writerow(row)\n",
    "                seen.add(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f2b64a-6b7d-4a47-b51a-9f65ee0bfa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for specie in species_list:\n",
    "    with open(f'full_table_{specie}.tsv', 'r') as inputfile, open(f'Missing_{specie}.tsv', 'w') as outputfile:\n",
    "        reader = csv.reader(inputfile, delimiter='\\t')\n",
    "        writer = csv.writer(outputfile, delimiter='\\t')\n",
    "        seen = set()\n",
    "        for row in reader:\n",
    "            if row[0] not in seen and 'Missing' in row:\n",
    "                writer.writerow(row)\n",
    "                seen.add(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a3da89-51bc-4099-b2e8-425a4676cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for specie in species_list:\n",
    "    with open(f'full_table_{specie}.tsv', 'r') as inputfile, open(f'Fragmented_{specie}.tsv', 'w') as outputfile:\n",
    "        reader = csv.reader(inputfile, delimiter='\\t')\n",
    "        writer = csv.writer(outputfile, delimiter='\\t')\n",
    "        seen = set()\n",
    "        for row in reader:\n",
    "            if row[0] not in seen and 'Fragmented' in row:\n",
    "                writer.writerow(row)\n",
    "                seen.add(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6966db34-787a-4ce9-b6b5-16159e96ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for specie in species_list:\n",
    "    with open(f'full_table_{specie}.tsv', 'r') as inputfile, open(f'Cleaned_{specie}.tsv', 'w') as outputfile:\n",
    "        reader = csv.reader(inputfile, delimiter='\\t')\n",
    "        writer = csv.writer(outputfile, delimiter='\\t')\n",
    "        seen = set()\n",
    "        for row in reader:\n",
    "            if row[0] not in seen:\n",
    "                writer.writerow(row)\n",
    "                seen.add(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f01f7de-2a28-4b3f-80b7-34afee3bfa8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Cleaned_Auxenochlorella_protothecoides_UTEX25.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCleaned_Auxenochlorella_protothecoides_UTEX25.tsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Cleaned_Auxenochlorella_protothecoides_UTEX25.tsv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Cleaned_Auxenochlorella_protothecoides_UTEX25.tsv', sep='\\t', skiprows=2)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
